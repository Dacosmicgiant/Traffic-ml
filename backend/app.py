# backend/app.py
"""
Updated Flask App with Phase 1: Persistent Storage & Enhanced Caching
====================================================================

This updated version integrates with the new PersistentRAGPipeline to provide:
- 5-10x faster startup times
- Enhanced FAQ caching with 50+ entries
- Persistent vector storage
- Improved error handling and monitoring

Phase 1 Features:
- Fast startup through persistent FAISS index
- Extended FAQ cache for common questions
- Document change detection and auto-rebuild
- Comprehensive health monitoring
"""

from flask import Flask, request, jsonify, send_from_directory
import json
import os
import subprocess
import time
import sys
import logging
from datetime import datetime

app = Flask(__name__, static_folder="../static", static_url_path="/static")

# Configure detailed logging
logging.basicConfig(
    level=logging.DEBUG, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def start_ollama_server():
    """Start Ollama server if not already running."""
    try:
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            app.logger.info("Ollama server is already running.")
            return None
        
        # Start Ollama server based on platform
        if sys.platform.startswith('win'):
            process = subprocess.Popen(
                ['start', '/B', 'ollama', 'serve'], 
                shell=True, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE
            )
        else:
            process = subprocess.Popen(
                ['nohup', 'ollama', 'serve'], 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE
            )
        
        # Wait for server to start
        time.sleep(5)
        
        # Verify server is running
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            app.logger.info("Ollama server started successfully.")
            return process
        else:
            app.logger.error("Failed to start Ollama server.")
            return None
            
    except Exception as e:
        app.logger.error(f"Error starting Ollama server: {str(e)}")
        return None

def initialize_rag_pipeline():
    """Initialize the RAG pipeline with error handling."""
    try:
        app.logger.info("Initializing Persistent RAG Pipeline...")
        start_time = time.time()
        
        # Import the new persistent pipeline
        from rag_pipeline import PersistentRAGPipeline
        
        # Initialize with optimized configuration
        config = {
            'ollama_model': 'tinyllama',
            'ollama_timeout': 30,
            'temperature': 0.3,
            'max_response_tokens': 500,
            'chunk_size': 600,
            'chunk_overlap': 100,
            'max_retrieval_chunks': 5
        }
        
        rag = PersistentRAGPipeline(config=config)
        
        initialization_time = time.time() - start_time
        app.logger.info(f"RAG pipeline initialized in {initialization_time:.2f} seconds")
        app.logger.info(f"Initialization method: {rag.pipeline_stats['initialization_method']}")
        app.logger.info(f"FAQ cache size: {len(rag.faq_cache)}")
        
        return rag
        
    except Exception as e:
        app.logger.error(f"Failed to initialize RAG pipeline: {str(e)}")
        return None

# Global variables
ollama_process = None
rag = None

# Application startup
print("üöÄ Starting Enhanced Motor Vehicles Act Chatbot (Phase 1)")
print("=" * 70)

# Step 1: Start Ollama server
print("üì° Starting Ollama server...")
ollama_process = start_ollama_server()

# Step 2: Initialize RAG pipeline
print("üß† Initializing RAG pipeline...")
rag = initialize_rag_pipeline()

if rag is None:
    print("‚ùå Failed to initialize RAG pipeline")
    print("‚ö†Ô∏è  Server will run in FAQ-only mode")
else:
    print("‚úÖ RAG pipeline initialized successfully")
    stats = rag.get_pipeline_stats()
    print(f"   Startup time: {stats['startup_time']:.2f}s")
    print(f"   Method: {stats['initialization_method']}")
    print(f"   Chunks: {stats['total_chunks']}")
    print(f"   FAQ entries: {stats['faq_cache_size']}")

print("=" * 70)

@app.route('/')
def serve_index():
    """Serve the main HTML interface."""
    app.logger.info("Serving index.html")
    return send_from_directory('../static', 'index.html')

@app.route('/query', methods=['POST'])
def handle_query():
    """
    Handle user queries with enhanced caching and error handling.
    """
    try:
        # Parse request
        data = request.json
        query = data.get('query', '').strip()
        
        if not query:
            app.logger.warning("Empty query received")
            return jsonify({
                'response': 'Please ask a question about the Motor Vehicles Act!',
                'source': 'validation_error'
            }), 400
        
        app.logger.info(f"Processing query: {query[:100]}...")
        start_time = time.time()
        
        # Check if RAG pipeline is available
        if rag is None:
            app.logger.error("RAG pipeline is not initialized")
            return jsonify({
                'response': (
                    "The advanced answering system is currently unavailable. "
                    "Please try a simple question like 'What is the penalty for driving without a license?' "
                    "or contact the administrator."
                ),
                'source': 'system_error'
            }), 503
        
        # Process query through RAG pipeline
        response = rag.process_query(query)
        processing_time = time.time() - start_time
        
        # Get updated statistics
        stats = rag.get_pipeline_stats()
        
        app.logger.info(f"Query processed in {processing_time:.2f}s")
        app.logger.info(f"Cache hit rate: {stats.get('cache_hit_rate', 0):.1f}%")
        
        return jsonify({
            'response': response,
            'processing_time': round(processing_time, 3),
            'cache_hit_rate': round(stats.get('cache_hit_rate', 0), 1),
            'source': 'rag_pipeline'
        })
        
    except Exception as e:
        app.logger.error(f"Error processing query: {str(e)}")
        return jsonify({
            'response': (
                f"I encountered an issue processing your query: {str(e)}. "
                f"Please try again or contact the administrator if the problem persists."
            ),
            'source': 'processing_error'
        }), 500

@app.route('/health', methods=['GET'])
def health_check():
    """
    Comprehensive health check endpoint for monitoring.
    """
    try:
        app.logger.info("Health check requested")
        
        health_data = {
            'timestamp': datetime.now().isoformat(),
            'server_status': 'running',
            'uptime': time.time() - app.start_time if hasattr(app, 'start_time') else 0
        }
        
        if rag is not None:
            # Get RAG pipeline health
            rag_health = rag.health_check()
            health_data['rag_pipeline'] = rag_health
            
            # Get pipeline statistics
            stats = rag.get_pipeline_stats()
            health_data['statistics'] = {
                'total_queries': stats['total_queries_processed'],
                'cache_hit_rate': round(stats.get('cache_hit_rate', 0), 1),
                'avg_response_time': round(stats.get('last_query_time', 0), 3),
                'faq_cache_size': stats['faq_cache_size'],
                'initialization_method': stats['initialization_method'],
                'startup_time': round(stats['startup_time'], 2)
            }
            
            # Determine overall health status
            overall_status = rag_health.get('overall_status', 'unknown')
            health_data['overall_status'] = overall_status
            
            status_code = 200 if overall_status == 'healthy' else 503
            
        else:
            health_data['rag_pipeline'] = {
                'overall_status': 'unavailable',
                'error': 'RAG pipeline not initialized'
            }
            health_data['overall_status'] = 'degraded'
            status_code = 503
        
        return jsonify(health_data), status_code
        
    except Exception as e:
        app.logger.error(f"Health check failed: {str(e)}")
        return jsonify({
            'timestamp': datetime.now().isoformat(),
            'overall_status': 'error',
            'error': str(e)
        }), 500

@app.route('/stats', methods=['GET'])
def get_statistics():
    """
    Get detailed pipeline statistics for monitoring and debugging.
    """
    try:
        if rag is None:
            return jsonify({
                'error': 'RAG pipeline not available',
                'timestamp': datetime.now().isoformat()
            }), 503
        
        stats = rag.get_pipeline_stats()
        
        # Add server-level information
        server_stats = {
            'server_timestamp': datetime.now().isoformat(),
            'server_uptime': time.time() - app.start_time if hasattr(app, 'start_time') else 0,
            'pipeline_stats': stats
        }
        
        return jsonify(server_stats)
        
    except Exception as e:
        app.logger.error(f"Error getting statistics: {str(e)}")
        return jsonify({
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/cache/clear', methods=['POST'])  
def clear_cache():
    """
    Clear specific cache levels (for admin use).
    """
    try:
        data = request.json or {}
        cache_type = data.get('cache_type', 'all')
        
        if rag is None:
            return jsonify({
                'error': 'RAG pipeline not available'
            }), 503
        
        # For Phase 1, we only have FAQ cache clearing
        if cache_type in ['all', 'faq']:
            # In future phases, implement cache clearing
            # For now, just return success
            return jsonify({
                'message': f'Cache clearing requested: {cache_type}',
                'note': 'Full cache clearing will be implemented in Phase 2',
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({
                'error': f'Unknown cache type: {cache_type}',
                'available_types': ['all', 'faq']
            }), 400
            
    except Exception as e:
        app.logger.error(f"Error clearing cache: {str(e)}")
        return jsonify({
            'error': str(e)
        }), 500

@app.route('/test', methods=['GET'])
def test_endpoint():
    """
    Test endpoint for basic connectivity and system status.
    """
    app.logger.info("Test endpoint accessed")
    
    test_result = {
        'status': 'Backend is running',
        'timestamp': datetime.now().isoformat(),
        'rag_status': 'Initialized' if rag else 'Failed',
        'ollama_status': 'Running' if ollama_process else 'Not managed by app'
    }
    
    if rag:
        stats = rag.get_pipeline_stats()
        test_result['quick_stats'] = {
            'initialization_method': stats['initialization_method'],
            'startup_time': round(stats['startup_time'], 2),
            'total_chunks': stats['total_chunks'],
            'faq_entries': stats['faq_cache_size']
        }
    
    return jsonify(test_result), 200

@app.teardown_appcontext
def cleanup(exception=None):
    """Clean up resources when application context tears down."""
    if ollama_process and sys.platform.startswith('win'):
        try:
            app.logger.info("Terminating Ollama process")
            subprocess.run(['taskkill', '/PID', str(ollama_process.pid), '/F'], shell=True)
        except Exception as e:
            app.logger.error(f"Error terminating Ollama process: {str(e)}")

# Error handlers
@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'error': 'Endpoint not found',
        'message': 'The requested endpoint does not exist'
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'error': 'Internal server error',
        'message': 'An unexpected error occurred'
    }), 500

if __name__ == '__main__':
    # Record application start time for uptime calculation
    app.start_time = time.time()
    
    app.logger.info("Starting Flask server on port 5000")
    print("\nüåê Server starting on http://localhost:5000")
    print("üìä Available endpoints:")
    print("   GET  /           - Web interface")
    print("   POST /query      - Process queries")
    print("   GET  /health     - Health check")
    print("   GET  /stats      - Detailed statistics")
    print("   GET  /test       - Basic connectivity test")
    print("   POST /cache/clear - Clear caches (admin)")
    print("\nüéØ Phase 1 Features Active:")
    print("   ‚úÖ Persistent vector storage")
    print("   ‚úÖ Enhanced FAQ cache (50+ entries)")
    print("   ‚úÖ Document change detection")
    print("   ‚úÖ Fast startup times")
    print("   ‚úÖ Comprehensive health monitoring")
    
    try:
        app.run(debug=True, host='0.0.0.0', port=5000)
    except KeyboardInterrupt:
        print("\nüõë Server shutdown requested")
        if ollama_process:
            print("üßπ Cleaning up Ollama process...")
    except Exception as e:
        print(f"\n‚ùå Server error: {str(e)}")
    finally:
        print("üëã Server stopped")